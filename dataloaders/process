#!/usr/bin/env python

import numpy as np
import os
import json
import sys
import importlib
import pprint

dataset_name = sys.argv[1]

dataset_dir = os.path.abspath(os.path.join(".", dataset_name))

if not os.path.isdir(dataset_dir):
    raise ValueError("Dataset {} does not exist.".format(dataset_dir))

dataset_module = importlib.import_module(dataset_name)

dataset = dataset_module.Dataset()

outdir = os.path.join("..", "datasets", dataset_name, "out")
os.makedirs(outdir, exist_ok=True)

class_members = dataset.get_class_members()
classes = dataset.get_classes()

for c in classes:
    assert c in class_members.keys(), "Class %s not defined in class members" % c
    assert isinstance(
        c, str), "Class %s should be a string, but found %s" % (c, type(c))

for c in class_members.keys():
    assert c in classes, "Class %s not defined in classes" % c

class_counts = [len(class_members[c]["eval_instances"]) +
                len(class_members[c]["train_instances"]) for c in class_members.keys()]
print("Class counts: %s" % dict(zip(classes, class_counts)))

for num_folds in range(2, 21):
    folds = dataset.split_folds(class_members, num_folds)
    with open(os.path.join(outdir, "%s-folds.json" % num_folds), "w") as outfile:
        json.dump({
            "folds": folds
        }, outfile, indent=4)

mean, std = dataset.process_images(
    lambda image, mask, name: np.savez_compressed(
        os.path.join(outdir, name), image=image, mask=mask)
)

print("Mean = {}".format(mean))
print("Std = {}".format(std))

with open(os.path.join(outdir, "classes.json"), "w") as outfile:
    json.dump({
        "properties": {
            "mean": mean,
            "std": std
        },
        "classes": class_members,
        "class_order": [str(s) for s in classes]
    }, outfile, indent=4)
